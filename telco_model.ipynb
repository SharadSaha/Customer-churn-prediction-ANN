{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "telco-model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY5AJQM428Sr"
      },
      "source": [
        "## **TELCO CUSTOMER CHURN DATASET**\n",
        "\n",
        "### **MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVAreGnA2KjC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "7JB6fyqN2clD",
        "outputId": "dca4e2e9-7257-46eb-a283-dcb9a539aaf0"
      },
      "source": [
        "df = pd.read_csv('/content/telco_churn_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "      <th>gender_Female</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>Partner_No</th>\n",
              "      <th>Partner_Yes</th>\n",
              "      <th>Dependents_No</th>\n",
              "      <th>Dependents_Yes</th>\n",
              "      <th>PhoneService_No</th>\n",
              "      <th>PhoneService_Yes</th>\n",
              "      <th>MultipleLines_No</th>\n",
              "      <th>MultipleLines_No phone service</th>\n",
              "      <th>MultipleLines_Yes</th>\n",
              "      <th>InternetService_DSL</th>\n",
              "      <th>InternetService_Fiber optic</th>\n",
              "      <th>InternetService_No</th>\n",
              "      <th>OnlineSecurity_No</th>\n",
              "      <th>OnlineSecurity_No internet service</th>\n",
              "      <th>OnlineSecurity_Yes</th>\n",
              "      <th>OnlineBackup_No</th>\n",
              "      <th>OnlineBackup_No internet service</th>\n",
              "      <th>OnlineBackup_Yes</th>\n",
              "      <th>DeviceProtection_No</th>\n",
              "      <th>DeviceProtection_No internet service</th>\n",
              "      <th>DeviceProtection_Yes</th>\n",
              "      <th>TechSupport_No</th>\n",
              "      <th>TechSupport_No internet service</th>\n",
              "      <th>TechSupport_Yes</th>\n",
              "      <th>StreamingTV_No</th>\n",
              "      <th>StreamingTV_No internet service</th>\n",
              "      <th>StreamingTV_Yes</th>\n",
              "      <th>StreamingMovies_No</th>\n",
              "      <th>StreamingMovies_No internet service</th>\n",
              "      <th>StreamingMovies_Yes</th>\n",
              "      <th>Contract_Month-to-month</th>\n",
              "      <th>Contract_One year</th>\n",
              "      <th>Contract_Two year</th>\n",
              "      <th>PaperlessBilling_No</th>\n",
              "      <th>PaperlessBilling_Yes</th>\n",
              "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
              "      <th>PaymentMethod_Credit card (automatic)</th>\n",
              "      <th>PaymentMethod_Electronic check</th>\n",
              "      <th>PaymentMethod_Mailed check</th>\n",
              "      <th>tenure-group_1 - 12</th>\n",
              "      <th>tenure-group_13 - 24</th>\n",
              "      <th>tenure-group_25 - 36</th>\n",
              "      <th>tenure-group_37 - 48</th>\n",
              "      <th>tenure-group_49 - 60</th>\n",
              "      <th>tenure-group_61 - 72</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  SeniorCitizen  ...  tenure-group_49 - 60  tenure-group_61 - 72\n",
              "0           0              0  ...                     0                     0\n",
              "1           1              0  ...                     0                     0\n",
              "2           2              0  ...                     0                     0\n",
              "3           3              0  ...                     0                     0\n",
              "4           4              0  ...                     0                     0\n",
              "\n",
              "[5 rows x 52 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "7a2Xkjhx2p5K",
        "outputId": "00362a19-c707-4a35-bc33-14dd07788712"
      },
      "source": [
        "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "df.head(2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "      <th>gender_Female</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>Partner_No</th>\n",
              "      <th>Partner_Yes</th>\n",
              "      <th>Dependents_No</th>\n",
              "      <th>Dependents_Yes</th>\n",
              "      <th>PhoneService_No</th>\n",
              "      <th>PhoneService_Yes</th>\n",
              "      <th>MultipleLines_No</th>\n",
              "      <th>MultipleLines_No phone service</th>\n",
              "      <th>MultipleLines_Yes</th>\n",
              "      <th>InternetService_DSL</th>\n",
              "      <th>InternetService_Fiber optic</th>\n",
              "      <th>InternetService_No</th>\n",
              "      <th>OnlineSecurity_No</th>\n",
              "      <th>OnlineSecurity_No internet service</th>\n",
              "      <th>OnlineSecurity_Yes</th>\n",
              "      <th>OnlineBackup_No</th>\n",
              "      <th>OnlineBackup_No internet service</th>\n",
              "      <th>OnlineBackup_Yes</th>\n",
              "      <th>DeviceProtection_No</th>\n",
              "      <th>DeviceProtection_No internet service</th>\n",
              "      <th>DeviceProtection_Yes</th>\n",
              "      <th>TechSupport_No</th>\n",
              "      <th>TechSupport_No internet service</th>\n",
              "      <th>TechSupport_Yes</th>\n",
              "      <th>StreamingTV_No</th>\n",
              "      <th>StreamingTV_No internet service</th>\n",
              "      <th>StreamingTV_Yes</th>\n",
              "      <th>StreamingMovies_No</th>\n",
              "      <th>StreamingMovies_No internet service</th>\n",
              "      <th>StreamingMovies_Yes</th>\n",
              "      <th>Contract_Month-to-month</th>\n",
              "      <th>Contract_One year</th>\n",
              "      <th>Contract_Two year</th>\n",
              "      <th>PaperlessBilling_No</th>\n",
              "      <th>PaperlessBilling_Yes</th>\n",
              "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
              "      <th>PaymentMethod_Credit card (automatic)</th>\n",
              "      <th>PaymentMethod_Electronic check</th>\n",
              "      <th>PaymentMethod_Mailed check</th>\n",
              "      <th>tenure-group_1 - 12</th>\n",
              "      <th>tenure-group_13 - 24</th>\n",
              "      <th>tenure-group_25 - 36</th>\n",
              "      <th>tenure-group_37 - 48</th>\n",
              "      <th>tenure-group_49 - 60</th>\n",
              "      <th>tenure-group_61 - 72</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SeniorCitizen  MonthlyCharges  ...  tenure-group_49 - 60  tenure-group_61 - 72\n",
              "0              0           29.85  ...                     0                     0\n",
              "1              0           56.95  ...                     0                     0\n",
              "\n",
              "[2 rows x 51 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST8bY5T33OWD"
      },
      "source": [
        "### **Creating the data and the label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZGsw4aN2xA6",
        "outputId": "23881d05-0a6e-49c5-8be6-15d70177200e"
      },
      "source": [
        "data = df.drop('Churn', axis=1)\n",
        "label = df['Churn']\n",
        "\n",
        "data.shape,label.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7032, 50), (7032,))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzjiXva03pL8"
      },
      "source": [
        "### **Splitting dataset into train and test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAEJAJ5Y3c8D"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKKbEIuj33dS",
        "outputId": "e9366a4b-1c57-44b7-b6a2-6defe8206503"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(data,label,test_size=0.2)\n",
        "x_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5625, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGxnps2U5E4c"
      },
      "source": [
        "### **ANN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqSKJH5G4MNC"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def model():\n",
        "  model = keras.Sequential([\n",
        "                              keras.layers.Dense(20,input_shape=(50,),activation='relu'),\n",
        "                              keras.layers.Dense(1,activation='sigmoid'),\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvYB3RC8HGbZ"
      },
      "source": [
        "**Training the initial ANN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT1bXlVG6Meh",
        "outputId": "4523695b-3e9e-45dc-bf78-d57e55108eae"
      },
      "source": [
        "model_ANN = model()\n",
        "model_ANN.fit(x_train,y_train,epochs=100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 23.9723 - accuracy: 0.6142\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5613 - accuracy: 0.7492\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.6666 - accuracy: 0.7511\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5015 - accuracy: 0.7813\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5455 - accuracy: 0.7819\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5440 - accuracy: 0.7835\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4828 - accuracy: 0.7835\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7851\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5824 - accuracy: 0.7780\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5094 - accuracy: 0.7879\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.7380 - accuracy: 0.7682\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.7899\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.6600 - accuracy: 0.7716\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5752 - accuracy: 0.7792\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5787 - accuracy: 0.7733\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5817 - accuracy: 0.7794\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.7801\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5387 - accuracy: 0.7828\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.7783\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5358 - accuracy: 0.7813\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5424 - accuracy: 0.7806\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7883\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5520 - accuracy: 0.7781\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7865\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5181 - accuracy: 0.7771\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5278 - accuracy: 0.7831\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5237 - accuracy: 0.7767\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5501 - accuracy: 0.7817\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5972 - accuracy: 0.7733\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.7120 - accuracy: 0.7682\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7849\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4920 - accuracy: 0.7909\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5108 - accuracy: 0.7792\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7861\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5304 - accuracy: 0.7813\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5656 - accuracy: 0.7797\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7879\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5481 - accuracy: 0.7783\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.7925\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5712 - accuracy: 0.7801\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7870\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5069 - accuracy: 0.7883\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5194 - accuracy: 0.7794\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5148 - accuracy: 0.7884\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5796 - accuracy: 0.7817\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5280 - accuracy: 0.7810\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5499 - accuracy: 0.7840\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5470 - accuracy: 0.7812\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5258 - accuracy: 0.7799\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5767 - accuracy: 0.7812\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5389 - accuracy: 0.7819\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4841 - accuracy: 0.7879\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4848 - accuracy: 0.7908\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5335 - accuracy: 0.7815\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5500 - accuracy: 0.7817\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5338 - accuracy: 0.7806\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4445 - accuracy: 0.7893\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4833 - accuracy: 0.7920\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5087 - accuracy: 0.7874\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5320 - accuracy: 0.7826\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5004 - accuracy: 0.7812\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.6083 - accuracy: 0.7748\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5132 - accuracy: 0.7831\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5489 - accuracy: 0.7817\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5912 - accuracy: 0.7746\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4484 - accuracy: 0.7959\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.7701\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4856 - accuracy: 0.7906\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5057 - accuracy: 0.7824\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5374 - accuracy: 0.7813\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.6109 - accuracy: 0.7771\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5290 - accuracy: 0.7852\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5500 - accuracy: 0.7849\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5736 - accuracy: 0.7783\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5390 - accuracy: 0.7794\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.7868\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4993 - accuracy: 0.7826\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5556 - accuracy: 0.7806\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5311 - accuracy: 0.7852\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5306 - accuracy: 0.7794\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4750 - accuracy: 0.7909\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5814 - accuracy: 0.7760\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4881 - accuracy: 0.7872\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.6858 - accuracy: 0.7728\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5316 - accuracy: 0.7815\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5100 - accuracy: 0.7854\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5275 - accuracy: 0.7820\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5621 - accuracy: 0.7792\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4764 - accuracy: 0.7876\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4822 - accuracy: 0.7861\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.7751\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5178 - accuracy: 0.7803\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4619 - accuracy: 0.7964\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5373 - accuracy: 0.7799\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5499 - accuracy: 0.7833\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5613 - accuracy: 0.7760\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5521 - accuracy: 0.7893\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.7938\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.7780\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.4988 - accuracy: 0.7849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6ad47f950>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV06fllC6ZBh",
        "outputId": "e2a56d38-2667-4ea7-8acb-8a0799573940"
      },
      "source": [
        "model_ANN.evaluate(x_test,y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 0s 3ms/step - loss: 1.1309 - accuracy: 0.7818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1309202909469604, 0.7818052768707275]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgzNrUusAaXz"
      },
      "source": [
        "predictions=model_ANN.predict(x_test)\n",
        "y_pred=[]\n",
        "for p in predictions:\n",
        "  if p>0.5:\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4PWol5Q-_f4",
        "outputId": "c018900b-a657-4467-8b79-c6253e689c96"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.96      0.87      1038\n",
            "           1       0.73      0.27      0.39       369\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.76      0.62      0.63      1407\n",
            "weighted avg       0.77      0.78      0.74      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5y4Svn0CeMS"
      },
      "source": [
        "### **Upsampling of data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT4yhPHBBU6H"
      },
      "source": [
        "from imblearn.combine import SMOTEENN"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STPSonxkCsU_"
      },
      "source": [
        "sm=SMOTEENN()\n",
        "x_upsampled,y_upsampled=sm.fit_resample(data,label)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTj913ZADBM2",
        "outputId": "332be509-cccb-4c9c-c756-05728b6ebf98"
      },
      "source": [
        "x_upsampled.shape,y_upsampled.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5822, 50), (5822,))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6qmknu5DitP"
      },
      "source": [
        "xr_train,xr_test,yr_train,yr_test=train_test_split(x_upsampled,y_upsampled,test_size=0.2)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGWU8eF4HQJ3"
      },
      "source": [
        "**Training the same model after upsampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_WTXhLUD53G",
        "outputId": "7bf2b68c-d8f9-48d0-beee-6773733a07c4"
      },
      "source": [
        "model = model()\n",
        "model.fit(xr_train,yr_train,epochs=100)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 4.9698 - accuracy: 0.7543\n",
            "Epoch 2/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3819 - accuracy: 0.8731\n",
            "Epoch 3/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4490 - accuracy: 0.8752\n",
            "Epoch 4/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2748 - accuracy: 0.8969\n",
            "Epoch 5/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8920\n",
            "Epoch 6/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2605 - accuracy: 0.9096\n",
            "Epoch 7/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.9132\n",
            "Epoch 8/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9205\n",
            "Epoch 9/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2969 - accuracy: 0.9083\n",
            "Epoch 10/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9169\n",
            "Epoch 11/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2567 - accuracy: 0.9214\n",
            "Epoch 12/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2279 - accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3177 - accuracy: 0.9167\n",
            "Epoch 14/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2380 - accuracy: 0.9294\n",
            "Epoch 15/100\n",
            "146/146 [==============================] - 1s 3ms/step - loss: 0.3697 - accuracy: 0.9070\n",
            "Epoch 16/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.9261\n",
            "Epoch 17/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9223\n",
            "Epoch 18/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3890 - accuracy: 0.9111\n",
            "Epoch 19/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2485 - accuracy: 0.9317\n",
            "Epoch 20/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2855 - accuracy: 0.9197\n",
            "Epoch 21/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2600 - accuracy: 0.9281\n",
            "Epoch 22/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2528 - accuracy: 0.9296\n",
            "Epoch 23/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2824 - accuracy: 0.9233\n",
            "Epoch 24/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.9163\n",
            "Epoch 25/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3014 - accuracy: 0.9238\n",
            "Epoch 26/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2508 - accuracy: 0.9313\n",
            "Epoch 27/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1898 - accuracy: 0.9399\n",
            "Epoch 28/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1699 - accuracy: 0.9472\n",
            "Epoch 29/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3115 - accuracy: 0.9225\n",
            "Epoch 30/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9369\n",
            "Epoch 31/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2871 - accuracy: 0.9238\n",
            "Epoch 32/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4042 - accuracy: 0.9163\n",
            "Epoch 33/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9384\n",
            "Epoch 34/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.5293 - accuracy: 0.9055\n",
            "Epoch 35/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9457\n",
            "Epoch 36/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.5074 - accuracy: 0.9066\n",
            "Epoch 37/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4928 - accuracy: 0.9107\n",
            "Epoch 38/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3547 - accuracy: 0.9227\n",
            "Epoch 39/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1777 - accuracy: 0.9455\n",
            "Epoch 40/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2447 - accuracy: 0.9334\n",
            "Epoch 41/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3038 - accuracy: 0.9306\n",
            "Epoch 42/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9371\n",
            "Epoch 43/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9431\n",
            "Epoch 44/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9427\n",
            "Epoch 45/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.9253\n",
            "Epoch 46/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.9229\n",
            "Epoch 47/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2704 - accuracy: 0.9343\n",
            "Epoch 48/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.9055\n",
            "Epoch 49/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2581 - accuracy: 0.9358\n",
            "Epoch 50/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.9300\n",
            "Epoch 51/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4843 - accuracy: 0.9126\n",
            "Epoch 52/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2340 - accuracy: 0.9392\n",
            "Epoch 53/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2410 - accuracy: 0.9401\n",
            "Epoch 54/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9452\n",
            "Epoch 55/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2359 - accuracy: 0.9399\n",
            "Epoch 56/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3592 - accuracy: 0.9221\n",
            "Epoch 57/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2543 - accuracy: 0.9347\n",
            "Epoch 58/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9431\n",
            "Epoch 59/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4174 - accuracy: 0.9186\n",
            "Epoch 60/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2232 - accuracy: 0.9405\n",
            "Epoch 61/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3124 - accuracy: 0.9341\n",
            "Epoch 62/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3486 - accuracy: 0.9289\n",
            "Epoch 63/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.9377\n",
            "Epoch 64/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9412\n",
            "Epoch 65/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2547 - accuracy: 0.9356\n",
            "Epoch 66/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2515 - accuracy: 0.9367\n",
            "Epoch 67/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2254 - accuracy: 0.9431\n",
            "Epoch 68/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.9334\n",
            "Epoch 69/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2171 - accuracy: 0.9399\n",
            "Epoch 70/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2908 - accuracy: 0.9334\n",
            "Epoch 71/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.9328\n",
            "Epoch 72/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2571 - accuracy: 0.9354\n",
            "Epoch 73/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1693 - accuracy: 0.9500\n",
            "Epoch 74/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9373\n",
            "Epoch 75/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.9321\n",
            "Epoch 76/100\n",
            "146/146 [==============================] - 1s 3ms/step - loss: 0.2377 - accuracy: 0.9371\n",
            "Epoch 77/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.9384\n",
            "Epoch 78/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2485 - accuracy: 0.9373\n",
            "Epoch 79/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3054 - accuracy: 0.9274\n",
            "Epoch 80/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4553 - accuracy: 0.9205\n",
            "Epoch 81/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2332 - accuracy: 0.9418\n",
            "Epoch 82/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9474\n",
            "Epoch 83/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2687 - accuracy: 0.9343\n",
            "Epoch 84/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2190 - accuracy: 0.9431\n",
            "Epoch 85/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2280 - accuracy: 0.9390\n",
            "Epoch 86/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2380 - accuracy: 0.9388\n",
            "Epoch 87/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.9373\n",
            "Epoch 88/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9433\n",
            "Epoch 89/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2819 - accuracy: 0.9319\n",
            "Epoch 90/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2633 - accuracy: 0.9382\n",
            "Epoch 91/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.9330\n",
            "Epoch 92/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2333 - accuracy: 0.9399\n",
            "Epoch 93/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2951 - accuracy: 0.9345\n",
            "Epoch 94/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9420\n",
            "Epoch 95/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9386\n",
            "Epoch 96/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2447 - accuracy: 0.9401\n",
            "Epoch 97/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9431\n",
            "Epoch 98/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2437 - accuracy: 0.9407\n",
            "Epoch 99/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2422 - accuracy: 0.9369\n",
            "Epoch 100/100\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9435\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6ad2a9dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve0bXFzLEA1P",
        "outputId": "da928a3a-8e22-482a-aef8-b44b0af2deff"
      },
      "source": [
        "model.evaluate(xr_test,yr_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.9073\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38628092408180237, 0.9072961211204529]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSztUOw2EJ39",
        "outputId": "3b48c839-37b0-43e9-99fd-b115586d6b00"
      },
      "source": [
        "predictions_new=model.predict(xr_test)\n",
        "yr_pred=[]\n",
        "for p in predictions_new:\n",
        "  if p>0.5:\n",
        "    yr_pred.append(1)\n",
        "  else:\n",
        "    yr_pred.append(0)\n",
        "\n",
        "print(classification_report(yr_test,yr_pred))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.97      0.90       513\n",
            "           1       0.97      0.86      0.91       652\n",
            "\n",
            "    accuracy                           0.91      1165\n",
            "   macro avg       0.91      0.91      0.91      1165\n",
            "weighted avg       0.92      0.91      0.91      1165\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmxvg1SvHV6w"
      },
      "source": [
        "### **Trying a new fine tuned model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1htHJIEaGu"
      },
      "source": [
        "def model2():\n",
        "  model = keras.Sequential([\n",
        "                              keras.layers.Dense(30,input_shape=(50,),activation='relu'),\n",
        "                              keras.layers.Dense(15,activation='relu'),\n",
        "                              keras.layers.Dense(1,activation='sigmoid'),\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBXfEZ46FDGO",
        "outputId": "7ef378fb-eef2-4d7a-a5f7-33e1a3ac9996"
      },
      "source": [
        "model2=model2()\n",
        "model2.fit(xr_train,yr_train,epochs=200)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 24.6433 - accuracy: 0.6313\n",
            "Epoch 2/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.8715 - accuracy: 0.8117\n",
            "Epoch 3/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4851 - accuracy: 0.8729\n",
            "Epoch 4/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4414 - accuracy: 0.8742\n",
            "Epoch 5/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4537 - accuracy: 0.8793\n",
            "Epoch 6/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3941 - accuracy: 0.8965\n",
            "Epoch 7/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2862 - accuracy: 0.9070\n",
            "Epoch 8/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9227\n",
            "Epoch 9/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4679 - accuracy: 0.8952\n",
            "Epoch 10/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.5756 - accuracy: 0.8922\n",
            "Epoch 11/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3409 - accuracy: 0.9107\n",
            "Epoch 12/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2481 - accuracy: 0.9212\n",
            "Epoch 13/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3113 - accuracy: 0.9098\n",
            "Epoch 14/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4662 - accuracy: 0.8963\n",
            "Epoch 15/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.6651 - accuracy: 0.8888\n",
            "Epoch 16/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.8903\n",
            "Epoch 17/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.9244\n",
            "Epoch 18/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3772 - accuracy: 0.9096\n",
            "Epoch 19/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.7258 - accuracy: 0.8894\n",
            "Epoch 20/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4797 - accuracy: 0.9130\n",
            "Epoch 21/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2348 - accuracy: 0.9364\n",
            "Epoch 22/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4034 - accuracy: 0.9175\n",
            "Epoch 23/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.9186\n",
            "Epoch 24/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4723 - accuracy: 0.9132\n",
            "Epoch 25/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3916 - accuracy: 0.9178\n",
            "Epoch 26/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4493 - accuracy: 0.9111\n",
            "Epoch 27/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.9356\n",
            "Epoch 28/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.9283\n",
            "Epoch 29/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.9279\n",
            "Epoch 30/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2892 - accuracy: 0.9261\n",
            "Epoch 31/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3008 - accuracy: 0.9266\n",
            "Epoch 32/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.9227\n",
            "Epoch 33/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.9178\n",
            "Epoch 34/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2621 - accuracy: 0.9317\n",
            "Epoch 35/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3107 - accuracy: 0.9279\n",
            "Epoch 36/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2315 - accuracy: 0.9343\n",
            "Epoch 37/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2683 - accuracy: 0.9279\n",
            "Epoch 38/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2699 - accuracy: 0.9341\n",
            "Epoch 39/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.9199\n",
            "Epoch 40/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.9148\n",
            "Epoch 41/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.9223\n",
            "Epoch 42/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9317\n",
            "Epoch 43/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2224 - accuracy: 0.9379\n",
            "Epoch 44/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.9347\n",
            "Epoch 45/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3622 - accuracy: 0.9227\n",
            "Epoch 46/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.7441 - accuracy: 0.8984\n",
            "Epoch 47/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.9233\n",
            "Epoch 48/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2714 - accuracy: 0.9347\n",
            "Epoch 49/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3057 - accuracy: 0.9266\n",
            "Epoch 50/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2487 - accuracy: 0.9347\n",
            "Epoch 51/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9392\n",
            "Epoch 52/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2220 - accuracy: 0.9377\n",
            "Epoch 53/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.9283\n",
            "Epoch 54/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.9296\n",
            "Epoch 55/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2518 - accuracy: 0.9326\n",
            "Epoch 56/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2233 - accuracy: 0.9360\n",
            "Epoch 57/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9375\n",
            "Epoch 58/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9343\n",
            "Epoch 59/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2844 - accuracy: 0.9272\n",
            "Epoch 60/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3406 - accuracy: 0.9212\n",
            "Epoch 61/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4423 - accuracy: 0.9120\n",
            "Epoch 62/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.9356\n",
            "Epoch 63/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2224 - accuracy: 0.9345\n",
            "Epoch 64/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.4546 - accuracy: 0.9135\n",
            "Epoch 65/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1944 - accuracy: 0.9427\n",
            "Epoch 66/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2458 - accuracy: 0.9356\n",
            "Epoch 67/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.9306\n",
            "Epoch 68/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3517 - accuracy: 0.9229\n",
            "Epoch 69/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9367\n",
            "Epoch 70/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9455\n",
            "Epoch 71/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9472\n",
            "Epoch 72/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2477 - accuracy: 0.9373\n",
            "Epoch 73/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2321 - accuracy: 0.9388\n",
            "Epoch 74/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2821 - accuracy: 0.9315\n",
            "Epoch 75/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.5601 - accuracy: 0.9053\n",
            "Epoch 76/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2890 - accuracy: 0.9324\n",
            "Epoch 77/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9358\n",
            "Epoch 78/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9332\n",
            "Epoch 79/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.9358\n",
            "Epoch 80/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9437\n",
            "Epoch 81/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2258 - accuracy: 0.9384\n",
            "Epoch 82/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2910 - accuracy: 0.9321\n",
            "Epoch 83/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.9362\n",
            "Epoch 84/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2756 - accuracy: 0.9311\n",
            "Epoch 85/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2132 - accuracy: 0.9414\n",
            "Epoch 86/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3106 - accuracy: 0.9279\n",
            "Epoch 87/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.9233\n",
            "Epoch 88/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9435\n",
            "Epoch 89/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9478\n",
            "Epoch 90/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9401\n",
            "Epoch 91/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2534 - accuracy: 0.9379\n",
            "Epoch 92/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2486 - accuracy: 0.9364\n",
            "Epoch 93/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2393 - accuracy: 0.9369\n",
            "Epoch 94/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2355 - accuracy: 0.9388\n",
            "Epoch 95/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9392\n",
            "Epoch 96/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9386\n",
            "Epoch 97/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2011 - accuracy: 0.9405\n",
            "Epoch 98/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1895 - accuracy: 0.9437\n",
            "Epoch 99/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9420\n",
            "Epoch 100/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9367\n",
            "Epoch 101/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9442\n",
            "Epoch 102/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2243 - accuracy: 0.9412\n",
            "Epoch 103/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1835 - accuracy: 0.9452\n",
            "Epoch 104/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1732 - accuracy: 0.9455\n",
            "Epoch 105/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9401\n",
            "Epoch 106/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2632 - accuracy: 0.9345\n",
            "Epoch 107/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9414\n",
            "Epoch 108/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2843 - accuracy: 0.9294\n",
            "Epoch 109/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9510\n",
            "Epoch 110/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9485\n",
            "Epoch 111/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2208 - accuracy: 0.9332\n",
            "Epoch 112/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9409\n",
            "Epoch 113/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.9403\n",
            "Epoch 114/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.9334\n",
            "Epoch 115/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.9339\n",
            "Epoch 116/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9474\n",
            "Epoch 117/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9418\n",
            "Epoch 118/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1835 - accuracy: 0.9446\n",
            "Epoch 119/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9371\n",
            "Epoch 120/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1781 - accuracy: 0.9482\n",
            "Epoch 121/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2196 - accuracy: 0.9431\n",
            "Epoch 122/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1781 - accuracy: 0.9446\n",
            "Epoch 123/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9470\n",
            "Epoch 124/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9540\n",
            "Epoch 125/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2415 - accuracy: 0.9336\n",
            "Epoch 126/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1631 - accuracy: 0.9476\n",
            "Epoch 127/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9498\n",
            "Epoch 128/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9427\n",
            "Epoch 129/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9493\n",
            "Epoch 130/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9397\n",
            "Epoch 131/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2361 - accuracy: 0.9356\n",
            "Epoch 132/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1729 - accuracy: 0.9452\n",
            "Epoch 133/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9373\n",
            "Epoch 134/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9517\n",
            "Epoch 135/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9534\n",
            "Epoch 136/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2348 - accuracy: 0.9328\n",
            "Epoch 137/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1787 - accuracy: 0.9442\n",
            "Epoch 138/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9491\n",
            "Epoch 139/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1469 - accuracy: 0.9513\n",
            "Epoch 140/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9459\n",
            "Epoch 141/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1585 - accuracy: 0.9476\n",
            "Epoch 142/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9452\n",
            "Epoch 143/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1426 - accuracy: 0.9500\n",
            "Epoch 144/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9437\n",
            "Epoch 145/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1573 - accuracy: 0.9467\n",
            "Epoch 146/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2435 - accuracy: 0.9373\n",
            "Epoch 147/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9463\n",
            "Epoch 148/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1509 - accuracy: 0.9480\n",
            "Epoch 149/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1473 - accuracy: 0.9487\n",
            "Epoch 150/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1818 - accuracy: 0.9403\n",
            "Epoch 151/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9487\n",
            "Epoch 152/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1563 - accuracy: 0.9427\n",
            "Epoch 153/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1328 - accuracy: 0.9502\n",
            "Epoch 154/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1325 - accuracy: 0.9493\n",
            "Epoch 155/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1394 - accuracy: 0.9521\n",
            "Epoch 156/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9517\n",
            "Epoch 157/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9401\n",
            "Epoch 158/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1438 - accuracy: 0.9467\n",
            "Epoch 159/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9474\n",
            "Epoch 160/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1252 - accuracy: 0.9532\n",
            "Epoch 161/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1251 - accuracy: 0.9540\n",
            "Epoch 162/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9495\n",
            "Epoch 163/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9502\n",
            "Epoch 164/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9553\n",
            "Epoch 165/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.9538\n",
            "Epoch 166/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1778 - accuracy: 0.9397\n",
            "Epoch 167/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9525\n",
            "Epoch 168/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1345 - accuracy: 0.9519\n",
            "Epoch 169/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1336 - accuracy: 0.9530\n",
            "Epoch 170/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9461\n",
            "Epoch 171/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9523\n",
            "Epoch 172/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9498\n",
            "Epoch 173/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1208 - accuracy: 0.9549\n",
            "Epoch 174/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1160 - accuracy: 0.9558\n",
            "Epoch 175/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9495\n",
            "Epoch 176/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9588\n",
            "Epoch 177/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9553\n",
            "Epoch 178/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9549\n",
            "Epoch 179/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9551\n",
            "Epoch 180/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1304 - accuracy: 0.9532\n",
            "Epoch 181/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9442\n",
            "Epoch 182/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1205 - accuracy: 0.9560\n",
            "Epoch 183/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1330 - accuracy: 0.9506\n",
            "Epoch 184/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1208 - accuracy: 0.9521\n",
            "Epoch 185/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1253 - accuracy: 0.9543\n",
            "Epoch 186/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1205 - accuracy: 0.9575\n",
            "Epoch 187/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1544 - accuracy: 0.9467\n",
            "Epoch 188/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1149 - accuracy: 0.9547\n",
            "Epoch 189/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9528\n",
            "Epoch 190/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9528\n",
            "Epoch 191/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9581\n",
            "Epoch 192/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1163 - accuracy: 0.9551\n",
            "Epoch 193/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9502\n",
            "Epoch 194/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1327 - accuracy: 0.9489\n",
            "Epoch 195/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9534\n",
            "Epoch 196/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9588\n",
            "Epoch 197/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9506\n",
            "Epoch 198/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1160 - accuracy: 0.9543\n",
            "Epoch 199/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9506\n",
            "Epoch 200/200\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6acf09a50>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avlSEneqF_bP",
        "outputId": "995d4dd5-ed27-4552-e3b0-666e5e2b1724"
      },
      "source": [
        "model2.evaluate(xr_test,yr_test)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14362238347530365, 0.940772533416748]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOXcU1N0GH32",
        "outputId": "495e7e0c-93b5-456d-cae5-06cca3e6898e"
      },
      "source": [
        "predictions_new=model2.predict(xr_test)\n",
        "yr_pred=[]\n",
        "for p in predictions_new:\n",
        "  if p>0.5:\n",
        "    yr_pred.append(1)\n",
        "  else:\n",
        "    yr_pred.append(0)\n",
        "\n",
        "print(classification_report(yr_test,yr_pred))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93       513\n",
            "           1       0.95      0.94      0.95       652\n",
            "\n",
            "    accuracy                           0.94      1165\n",
            "   macro avg       0.94      0.94      0.94      1165\n",
            "weighted avg       0.94      0.94      0.94      1165\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDwY0D2WH19G"
      },
      "source": [
        "## **Final model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf_pWO7CKULN",
        "outputId": "ec7b7c11-f5e5-4462-f106-979d11d72ae9"
      },
      "source": [
        "final_model = model2\n",
        "final_model.evaluate(xr_test,yr_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14362238347530365, 0.940772533416748]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl2qpn_XLJBH"
      },
      "source": [
        "### **Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XGSjMqkK-fN",
        "outputId": "e37db4ee-c986-4610-f292-0d76c9f92df5"
      },
      "source": [
        "print(classification_report(yr_test,yr_pred))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93       513\n",
            "           1       0.95      0.94      0.95       652\n",
            "\n",
            "    accuracy                           0.94      1165\n",
            "   macro avg       0.94      0.94      0.94      1165\n",
            "weighted avg       0.94      0.94      0.94      1165\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "0J9RxftDLQJt",
        "outputId": "8909bec1-10bb-49f9-e111-88c30d1016cf"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "con_mat = tf.math.confusion_matrix(labels = yr_test,predictions = yr_pred)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(con_mat,annot=True,fmt='d')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nradxe9MvrQ"
      },
      "source": [
        "### **Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT57FNewMG_N",
        "outputId": "0cee9d62-954d-4b99-8d14-678661075c78"
      },
      "source": [
        "import pickle\n",
        "\n",
        "file_path='model.sav'\n",
        "pickle.dump(final_model,open(file_path,'wb'))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://4f5e99da-1f14-4f4d-977a-2d0be7d7bcdc/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIydvqr5NOJk",
        "outputId": "bdae594b-d96a-4a70-e9eb-c61617174db1"
      },
      "source": [
        "loaded_model = pickle.load(open(file_path,'rb'))\n",
        "loaded_model.evaluate(xr_test,yr_test)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14362238347530365, 0.940772533416748]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia6_6OYUN2vb"
      },
      "source": [
        "xr_train.to_csv('X_train.csv')\n",
        "xr_test.to_csv('X_test.csv')\n",
        "yr_train.to_csv('Y_train.csv')\n",
        "yr_test.to_csv('Y_test.csv')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0H8dhnnOTYE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}